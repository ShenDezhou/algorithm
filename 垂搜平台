
场景示例
目标：解决垂直领域的通用问题

舆情分析，领域知识图谱；金融，销售，政府

场景1：特定领域的非结构化文本数据分析，舆情领域，包括以下功能：

关键词提取、情感判断、分类或聚类、基于语义的查询（相对于词匹配，需要实现语义匹配，例如基于word2vec向量的检索，或使用相关词/扩展词进行检索）、自动类别判断、推荐集合内其他数据、搜索引擎的相关query推荐

场景2：垂直领域的相关推荐

指定站点网页的爬取，以及这些网页间的推荐计算

 

数据来源
Spider：已有webdriver，appdriver

数据文件，其他异构源的导入：Kafka，db，hdfs

ETL
机制：插件

提取时处理；后处理

预置功能包根据数据分布，给出建议，分析和处理

        引入知立方项目的normalize模块

子属性提取，分列，分行

 

AI：数据的进一步处理、关联、分析
实现方案
模型封装及管理
docker封装服务
预置训练好的模型，提供接口。先实现此方案，给出可用的场景。
使用tornado提供基于python的http接口
基于其他语言及server的服务
提供模型/代码的上传
模型、数据文件的上传及管理（增、删、配置、查询）
模型服务实例的管理：配置、启动、停止、删除；或自动化的完成这类任务
tensorflow-serving：https:www.tensorflow.org/serving/
数据管理
针对每条数据进行处理，每条数据处理完成后，回填至原数据集的不同字段
新建数据集，每条数据处理完成后，处理结果和/或源数据填入到新数据集中
新建数据集，基于全量或抽样数据得到结果，结果填入到新数据集中，用途：模型训练或数据统计
提供便捷的上传下载功能
可用于数据处理、挖掘、模型训练
调用方式
每条数据对应一次或多次接口调用
单条数据针对一个字段调用一个接口
单条数据针对一组字段（dict的key或value）调用一个接口。
如果参数是dict或列表，需先扁平化或赋予一个id，用于对齐数据
单条数据针对不同字段调用多次接口
可以batch处理
针对整个数据集调用接口，以便得到全局处理信息。接口可以全量或抽样的方式获取数据并处理。需要开发挖掘任务调度系统
调用时机
数据抓取时
按时间/数据量触发
手动提交
测试
应提供测试功能，便于查看预期效果
在提交配置前，需完成测试，以确保功能正常
测试时，将进行一次或多次接口调用，由开发人员判断接口调用结果是否符合预期
接口格式
RESTFUL接口格式模板
输入：id+字段的列表
样例
NLP

基础NLP能力
分词，词性标注，依存句法分析：jieba分词/Hanlp/搜狗分词等
sklearn
word2vec服务，lda服务，sentence2vec服务

分类聚类
数据表到大类别的自动分类
自动扫描建议执行
预置分类模型

核心词自动提取
jieba-tfidf
jieba-textrank
同时做intention和slot-filling：https:github.com/HadoopIt/rnn-nlu
核心词扩展
基于相关推荐的核心词扩展：hintquery，hintterm，hinttopic
王东组核心词扩展工具
情感倾向
基于朴素贝叶斯，提供最基本功能
查询和检索

检索    
Query通过预置分类到大类别
自动给出一些可能的query及查询pattern
通过分析数据类型及分布，遍历或自动给出检索模板建议
基于分类，进行检索/问答
显示
通过分析数据类型及分布，自动给出建议显示的数据及布局模板
导出
模板+数据，xml，json
推荐
    查询的扩展：单条/多条结果的相似结果，或符合特定需求的结果

    数据的关联：同任务/同类型任务/其他数据表：数据的自动/半自动关联

    基于核心词的自动关联：自动扩展：数据集扩充建议（通过搜索引擎采样）

统计和summary
    理解数据集：统计，profile

知识图谱
norm，merge，关联，inference，检索

智能化：总结之前图谱项目中的各项需求，集成工具套件，做成自动化的构建工具

自动化的QO模板生成：自然语言自动生成查询模板，依存句法分析

 

智能标注
特征挖掘、目标label标注

在线/离线模型训练

预测精度统计及反馈，待标注数据重排序

参考资料：

https://github.com/crownpku/Chinese-Annotator

https://prodi.gy/docs/

智能监控
触发器：数据内容，数据量，系统

动作：日志；报警：外接报警接口

智能链接分析
参考：http:regex.inginf.units.it/

http://txt2re.com/
