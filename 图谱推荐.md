#SESSION离线数据制作：
大致思想：某个用户1小时内搜了a和b（a和b是共现pair），则a和b有一定相关性。B对于a的相关性与pair共现次数成正比，与b在其他所有共现pair中出现次数成反比。
1.      从${CONF}/sogou_rank.status中读取得到上次制作数据成功的日期。从上次数据制作成功日期开始到当前时间，按天计算每天的session数据。
（a）    Map端解析sogourank数据，抽取用户使用搜狗和百度搜索过的query
（b）    按小时将用户的query聚合在一起
（c）     对每个小时出现的query，两两组合在一起（两两组合的query，至少要有一个是实体，这一步得到的结果即是query-entity对）
（d）    统计query-entity对统计出现次数，可以看作TF值

2.      ${BIN}time_session.sh对session数据做时效性拟合，距离当前日期越近的数据，权重越高。计算公式：(1.08**(31-days))/3 + 1，days就是距离当前日期的天数。

3.      计算实体的IDF值，分两步：
（a）    统计每个实体在所有pair中出现次数，记为DF
（b）    上一步中所有实体的DF相加记为SUM，IDF=SUM/DF

4.      通过qo.dic将query转化为相对热门的query，将步骤1和步骤3计算出来的TF和sqrt（IDF）相乘则得到query和entity的相关值

5.      将query对应的entity以及相关值聚合到一起，并计算出feature.stat。feature.stat的最后三列用1和0分别表示session、text、title是否存在hint query，其中倒数第三列（表示session）的值可能为2，这时表示该hint query的session结果比较好。

6.      将步骤4的结果经过黑名单、融合其他数据、插入实体id以后，同text、title数据制作成disk

tupuhint数据制作流程:
tupuhint数据制作流程整体是放在session数据制作流程里运行的，/search/odin/offlinedata/bin/insertdoctermid.sh 生成最终二进制索引(使用genIndex3 这个可执行文件生成,输入是上述流程生成的feature.stat)

#Query与实体文本相似度计算：
大致思想：计算hint query和实体的文本相似度，取相似度较高的实体。相似度计算结合了文本向量、lda向量、word2vec向量相似度、pv等

#Query与实体相似度计算（实体对齐）：
大致思想：计算hint query和session数据中同名实体e1，e2…en的文本相似度，取相似度最高的实体id。例如，实体名称为李娜的至少有两个，分别是网球运动员和歌手。假设hint query为“网球大满贯”，则该query与网球运动员李娜文本相似度更高，假设hint query为“青藏高原歌词”，则该query与歌手李娜相似度更高

计算步骤：
1.               总计算流程10.134.14.120: /search/data1/xiaoc/session_en_id/ build.sh（代码均在该路径下，包括下面相对路径的代码）
2.               计算实体文本向量：10.134.14.120: /search/data1/xiaoc/session_en_id/ build_baike_vec.sh
3.               计算同名实体的文本向量：./bin/get_duplicate_vec.py
4.               将数据格式整理成二次排序所需要的格式./bin/srun_merge_data1.sh
5.               计算lda、word2vec向量：./bin/hq_vec_all_feature.sh
6.               由于百度、淘宝等实体被推荐频率较高，而二次排序作partition的key为实体名称，因此会导致二次排序过程中单个reducer计算时间过长。为解决该问题，将被推荐频率过高的实体分开计算。计算hq与df值小于800实体的相似度：sh cal_all_cos.sh；计算hq与df值大于800实体的相似度：sh srun_cal_cossim_big.sh
7.               归并上一步计算的结果：./bin/srun_merge_cos_result.sh

图谱hint query与商业化物料相关性计算：
10.134.14.120:/search/data2/xiaoc/hq2word
该计算流程与text数据计算流程大致一样，唯一的不同是候选集由实体变成了物料，因此需要重新抓取物料左侧搜索结果，制作成文本向量、lda向量、w2v向量，并拷贝到10.134.116.34: /search/odin/recommendertest/data路径下

相关功能：
1.      getalldocpage.add_hq.sh:调用搜狗内部接口，对物料进行搜狗搜索，取相关性前100的doc
2.      把物料对应的doc制作成为文本向量、lda向量、w2v向量（分别是tmp/hq_w2v、 tmp/hq、_vec tmp/hq_lda三个文件），并拷贝到10.134.116.34: /search/odin/recommendertest/data路径下，在116.34上重启recommender，注意start.sh中的配置文件必须是httpword.cfg
3.      多进程执行getPageRelEntity.php脚本，向116.34上的recommender打请求，以计算hint query和物料的相似度，最终结果保存在tmp/doc.vec.allfeature.*中
